import os
import json
import re
import time
from googleapiclient.discovery import build
from google.oauth2 import service_account
from datetime import datetime, timedelta, timezone
from googleapiclient.errors import HttpError
import html

# å¾ç’°å¢ƒè®Šé‡ä¸­è®€å– Google API æ†‘è­‰
google_sheets_credentials = os.getenv('GOOGLE_SHEETS_CREDENTIALS')
google_api_key = os.getenv('GOOGLE_API_KEY')

if not google_sheets_credentials or not google_api_key:
    raise ValueError("ç¼ºå°‘Google APIæ†‘è­‰æˆ–APIå¯†é‘°")

try:
    credentials_info = json.loads(google_sheets_credentials)
    credentials = service_account.Credentials.from_service_account_info(credentials_info)
except Exception as e:
    raise ValueError("ç„¡æ•ˆçš„Google Sheetsæ†‘è­‰") from e

# YouTube Data API å®¢æˆ¶ç«¯
youtube = build('youtube', 'v3', developerKey=google_api_key)

def get_video_date(video_id):
    """ç²å–å½±ç‰‡çš„å¯¦éš›ç›´æ’­æ—¥æœŸ"""
    try:
        request = youtube.videos().list(
            part='liveStreamingDetails,snippet',
            id=video_id
        )
        response = request.execute()
        
        if not response['items']:
            print(f"DEBUG: ç„¡æ³•æ‰¾åˆ°å½±ç‰‡ {video_id} çš„è³‡è¨Š")
            return None
        
        video_details = response['items'][0]
        
        # æ·»åŠ èª¿è©¦è¨Šæ¯
        print(f"DEBUG: å½±ç‰‡ {video_id} çš„è³‡è¨Šï¼š")
        print(f"DEBUG: å½±ç‰‡é¡å‹: {video_details['snippet'].get('liveBroadcastContent')}")
        print(f"DEBUG: æ¨™é¡Œ: {video_details['snippet'].get('title')}")
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæœƒå“¡é™å®šç›´æ’­
        if video_details['snippet'].get('liveBroadcastContent') == 'membersOnly':
            print(f"DEBUG: è·³éæœƒå“¡é™å®šè¦–é »ï¼š{video_id}")
            return None
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºç›´æ’­å½±ç‰‡
        if 'liveStreamingDetails' in video_details:
            # ä½¿ç”¨ç›´æ’­é–‹å§‹æ™‚é–“
            actual_start_time = video_details['liveStreamingDetails'].get('actualStartTime')
            if actual_start_time:
                # ç›´æ¥è§£ææ™‚é–“ï¼Œé€™å·²ç¶“æ˜¯ç•¶åœ°æ™‚é–“
                stream_date = datetime.strptime(actual_start_time, '%Y-%m-%dT%H:%M:%SZ')
                return stream_date.date()
        
        # å¦‚æœä¸æ˜¯ç›´æ’­æˆ–æ²’æœ‰ç›´æ’­æ™‚é–“ï¼Œä½¿ç”¨ç™¼å¸ƒæ™‚é–“
        publish_time = video_details['snippet']['publishedAt']
        publish_date = datetime.strptime(publish_time, '%Y-%m-%dT%H:%M:%SZ')
        return publish_date.date()
    except HttpError as e:
        print(f"Error fetching video date for {video_id}: {e}")
        return None

def get_video_ids_from_playlist(playlist_id):
    """å¾æ’­æ”¾æ¸…å–®ç²å–å½±ç‰‡IDå’Œæ—¥æœŸ"""
    video_info = []
    
    # è¨ˆç®—æœ€è¿‘30å¤©çš„æ—¥æœŸ
    thirty_days_ago = datetime.now(timezone.utc) - timedelta(days=30)
    # æ ¼å¼åŒ–æˆ RFC 3339 æ ¼å¼
    published_after = thirty_days_ago.strftime('%Y-%m-%dT%H:%M:%SZ')
    
    request = youtube.playlistItems().list(
        part='contentDetails,snippet',  # æ·»åŠ  snippet
        playlistId=playlist_id,
        maxResults=50
    )
    
    while request:
        try:
            response = request.execute()
            for item in response['items']:
                video_id = item['contentDetails']['videoId']
                video_date = get_video_date(video_id)
                
                if video_date and video_date >= thirty_days_ago.date():
                    video_info.append((video_id, video_date))
                    print(f"æ‰¾åˆ°å½±ç‰‡ï¼š{video_id} ä¾†è‡ª {video_date}")
                    
            request = youtube.playlistItems().list_next(request, response)
        except HttpError as e:
            print(f"Error fetching playlist items: {e}")
            break
    
    return video_info

def get_video_ids_from_channel(channel_id, query):
    """å¾é »é“ç²å–å½±ç‰‡IDå’Œæ—¥æœŸï¼Œæ ¹æ“šæ¨™é¡Œç¯©é¸"""
    video_info = []
    
    # è¨ˆç®—æœ€è¿‘30å¤©çš„æ—¥æœŸ
    thirty_days_ago = datetime.now(timezone.utc) - timedelta(days=30)
    # æ ¼å¼åŒ–æˆ RFC 3339 æ ¼å¼
    published_after = thirty_days_ago.strftime('%Y-%m-%dT%H:%M:%SZ')
    
    request = youtube.search().list(
        part='snippet',
        channelId=channel_id,
        q=query,
        maxResults=50,
        order='date',
        publishedAfter=published_after  # æ·»åŠ é€™è¡Œ
    )
    
    while request:
        try:
            response = request.execute()
            for item in response['items']:
                # åªè™•ç†å½±ç‰‡å‹æ…‹
                if item['id']['kind'] != 'youtube#video':
                    continue
                video_id = item['id']['videoId']
                video_date = get_video_date(video_id)
                print(f"DEBUG: {video_id}, {video_date}")  # åŠ é€™è¡Œè§€å¯Ÿ
                if video_date and video_date >= thirty_days_ago.date():
                    video_info.append((video_id, video_date))
                    print(f"æ‰¾åˆ°å½±ç‰‡ï¼š{video_id} ä¾†è‡ª {video_date}")
            request = youtube.search().list_next(request, response)
        except HttpError as e:
            print(f"Error fetching channel videos: {e}")
            break
    return video_info

def get_timestamp_comment(video_id):
    """ç²å–åŒ…å«æ™‚é–“æˆ³æ¨™è¨˜çš„ç•™è¨€"""
    try:
        request = youtube.commentThreads().list(
            part='snippet,replies',
            videoId=video_id,
            maxResults=100
        )

        while request:
            response = request.execute()
            for item in response['items']:
                # æª¢æŸ¥é ‚ç´šè©•è«–
                comment = item['snippet']['topLevelComment']['snippet']['textDisplay']
                if 'ğŸ’ğŸŒŸğŸ¶ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ğŸ’ğŸŒŸğŸ¶' in comment or 'ğŸŒŸğŸ’ğŸ¶ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ğŸŒŸğŸ’ğŸ¶' in comment:
                    return comment
                
                # æª¢æŸ¥å›è¦†è©•è«–
                if 'replies' in item:
                    for reply in item['replies']['comments']:
                        reply_comment = reply['snippet']['textDisplay']
                        if 'ğŸ’ğŸŒŸğŸ¶ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ğŸ’ğŸŒŸğŸ¶' in reply_comment or 'ğŸŒŸğŸ’ğŸ¶ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ğŸŒŸğŸ’ğŸ¶' in reply_comment:
                            return reply_comment

            request = youtube.commentThreads().list_next(request, response)
    
    except HttpError as e:
        print(f"Error fetching comments for video {video_id}: {e}")
        return None

    return None

def clean_html(raw_html):
    """ç§»é™¤HTMLæ¨™ç±¤ä¸¦è™•ç†æ›è¡Œå’Œç‰¹æ®Šå­—ç¬¦"""
    clean_text = re.sub(r'<br\s*/?>', '\n', raw_html)  # æ›¿æ› <br> ç‚ºæ›è¡Œç¬¦
    clean_text = re.sub(r'<.*?>', '', clean_text)  # ç§»é™¤å…¶ä»–HTMLæ¨™ç±¤
    clean_text = html.unescape(clean_text)  # è½‰æ›HTMLå¯¦é«”ç‚ºæ™®é€šå­—ç¬¦
    return clean_text

def save_to_file(video_id, comment, date):
    """ä¿å­˜ç•™è¨€åˆ°æ–‡ä»¶"""
    if not comment:
        print(f"æœªæ‰¾åˆ°æ™‚é–“æˆ³ç•™è¨€ï¼Œè¦–é »IDï¼š{video_id}")
        return
        
    output_dir = 'timeline'
    os.makedirs(output_dir, exist_ok=True)
    
    file_name = date.strftime('%Y%m%d') + '.txt'
    file_path = os.path.join(output_dir, file_name)
    
    # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(file_path):
        print(f"æ—¥æœŸç‚º {file_name} çš„æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³éã€‚")
        return
    
    # æ¸…ç†HTMLæ¨™ç±¤
    clean_comment = clean_html(comment)
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(f'ID = {video_id}\n')
        f.write(clean_comment)
        
    print(f"å·²ä¿å­˜æ™‚é–“æˆ³ç•™è¨€åˆ° {file_path}")

def main():
    playlist_id = 'PL7H5HbMMfm_lUoLIkPAZkhF_W0oDf5WEk'
    channel_id = 'UCwBJ-8LQYd7lZ7uW-4Adt4Q'

    print(f"DEBUG: é–‹å§‹æ™‚é–“: {datetime.now(timezone.utc)}")
    print(f"DEBUG: æœç´¢æœ€è¿‘30å¤©çš„å½±ç‰‡")
    
    # å°‡ query è¨­ç‚ºç©ºå­—ä¸²ï¼ŒæŠ“å…¨éƒ¨è¿‘ 30 å¤©å½±ç‰‡
    video_info = get_video_ids_from_playlist(playlist_id)
    print(f"DEBUG: å¾æ’­æ”¾æ¸…å–®æ‰¾åˆ° {len(video_info)} å€‹å½±ç‰‡")
    
    channel_videos = get_video_ids_from_channel(channel_id, "æ­Œæ ")
    print(f"DEBUG: å¾é »é“æ‰¾åˆ° {len(channel_videos)} å€‹æ­Œæ å½±ç‰‡")
    
    video_info += channel_videos

    batch_size = 10
    for i in range(0, len(video_info), batch_size):
        batch_videos = video_info[i:i + batch_size]
        for video_id, video_date in batch_videos:
            file_name = video_date.strftime('%Y%m%d') + '.txt'
            file_path = os.path.join('timeline', file_name)
            if os.path.exists(file_path):
                print(f"æ—¥æœŸç‚º {file_name} çš„æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³éè¦–é »ID {video_id}ã€‚")
                continue

            print(f"è™•ç†è¦–é » {video_id} ä¾†è‡ª {video_date}")
            timestamp_comment = get_timestamp_comment(video_id)
            if timestamp_comment:
                save_to_file(video_id, timestamp_comment, video_date)
        time.sleep(2)

if __name__ == '__main__':
    main()
